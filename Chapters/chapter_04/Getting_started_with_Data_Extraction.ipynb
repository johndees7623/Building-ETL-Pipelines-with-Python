{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a4e05f",
   "metadata": {},
   "source": [
    "## Data sourcing\n",
    "\n",
    "Source data from various source systems and ingest them using python code.\n",
    "\n",
    "1. Parquet files\n",
    "2. CSV files\n",
    "3. APIs\n",
    "4. RDBMS databases\n",
    "5. HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7de7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:27:21.174023Z",
     "start_time": "2024-04-09T15:27:17.315740Z"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "from unicodedata import normalize\n",
    "import http"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746175dc",
   "metadata": {},
   "source": [
    "### Sourcing Parquet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c37682",
   "metadata": {},
   "source": [
    "Please visit the url https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132b5dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:27:22.106986Z",
     "start_time": "2024-04-09T15:27:21.176063Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yellow_tripdata_2022-01.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Read data from the Parquet file. We use pandas read_parquet method for ease and speed.\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_parquet \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myellow_tripdata_2022-01.parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m df_parquet\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m~\\.virtualenvs\\Building-ETL-Pipelines-with-Python-QfMNJpYI\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001B[0m, in \u001B[0;36mread_parquet\u001B[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001B[0m\n\u001B[0;32m    664\u001B[0m     use_nullable_dtypes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    665\u001B[0m check_dtype_backend(dtype_backend)\n\u001B[1;32m--> 667\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_nullable_dtypes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\Building-ETL-Pipelines-with-Python-QfMNJpYI\\Lib\\site-packages\\pandas\\io\\parquet.py:267\u001B[0m, in \u001B[0;36mPyArrowImpl.read\u001B[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    265\u001B[0m     to_pandas_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit_blocks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m path_or_handle, handles, filesystem \u001B[38;5;241m=\u001B[39m \u001B[43m_get_path_or_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    274\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mparquet\u001B[38;5;241m.\u001B[39mread_table(\n\u001B[0;32m    275\u001B[0m         path_or_handle,\n\u001B[0;32m    276\u001B[0m         columns\u001B[38;5;241m=\u001B[39mcolumns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    280\u001B[0m     )\n",
      "File \u001B[1;32m~\\.virtualenvs\\Building-ETL-Pipelines-with-Python-QfMNJpYI\\Lib\\site-packages\\pandas\\io\\parquet.py:140\u001B[0m, in \u001B[0;36m_get_path_or_handle\u001B[1;34m(path, fs, storage_options, mode, is_dir)\u001B[0m\n\u001B[0;32m    130\u001B[0m handles \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m fs\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dir\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;66;03m# fsspec resources can also point to directories\u001B[39;00m\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001B[39;00m\n\u001B[1;32m--> 140\u001B[0m     handles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     fs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     path_or_handle \u001B[38;5;241m=\u001B[39m handles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\.virtualenvs\\Building-ETL-Pipelines-with-Python-QfMNJpYI\\Lib\\site-packages\\pandas\\io\\common.py:882\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    874\u001B[0m             handle,\n\u001B[0;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    879\u001B[0m         )\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    883\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    885\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'yellow_tripdata_2022-01.parquet'"
     ]
    }
   ],
   "source": [
    "# Read data from the Parquet file. We use pandas read_parquet method for ease and speed.\n",
    "df_parquet = pd.read_parquet(\"yellow_tripdata_2022-01.parquet\")\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2f93c",
   "metadata": {},
   "source": [
    "### Sourcing CSV data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a306a2",
   "metadata": {},
   "source": [
    "Please visit the url https://data.cityofnewyork.us/resource/h9gi-nx95.csv?$limit=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56007303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:27:22.110013Z",
     "start_time": "2024-04-09T15:27:22.109015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data from the CSV file. We use pandas read_csv method for ease and speed.\n",
    "df_csv = pd.read_csv(\"h9gi-nx95.csv\")\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da41e6",
   "metadata": {},
   "source": [
    "### Sourcing data from APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc77b5",
   "metadata": {},
   "source": [
    "Please make sure to install the certifi library using - pipenv install certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a061b34",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-09T15:27:22.111018Z"
    }
   },
   "outputs": [],
   "source": [
    "# get api data from url\n",
    "url = 'https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500'\n",
    "\n",
    "# Check if API is available to retrieve the data\n",
    "apt_status = request('GET', url).status #removed http. from the function in front of request\n",
    "print(apt_status)\n",
    "if apt_status == 200:\n",
    "    # Sometimes we get certificate error . We shoul never silence this error as this may cause a securirty threat.\n",
    "    # Create a Pool manager that can be used to read the API response \n",
    "    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "    data = json.loads(request('GET', url).data.decode('utf-8')) #removed http. from the function in front of request\n",
    "    df_api = pd.json_normalize(data)\n",
    "else:\n",
    "    df_api = pd.Dataframe()\n",
    "df_api.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fc78f",
   "metadata": {},
   "source": [
    "### Sourcing Data from RDBMS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a384b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T15:27:22.114012Z",
     "start_time": "2024-04-09T15:27:22.113014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "with sqlite3.connect(\"movies.sqlite\") as conn:\n",
    "    df = pd.read_sql(\"SELECT * from movies\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab324ee5",
   "metadata": {},
   "source": [
    "# Sourcing data from Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff92439",
   "metadata": {},
   "source": [
    "Please visit the url https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from url\n",
    "df_html = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)',match = 'by country')\n",
    "# Let's see how many tables are there with tage ' by county'\n",
    "print(len(df_html)) # There are 4 tables\n",
    "# Let's see the first table\n",
    "df_html[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
