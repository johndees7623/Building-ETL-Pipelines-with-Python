{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a4e05f",
   "metadata": {},
   "source": [
    "## Data sourcing\n",
    "\n",
    "Source data from various source systems and ingest them using python code.\n",
    "\n",
    "1. Parquet files\n",
    "2. CSV files\n",
    "3. APIs\n",
    "4. RDBMS databases\n",
    "5. HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7de7f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:25:10.972991Z",
     "start_time": "2024-04-09T20:25:10.887432Z"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "from unicodedata import normalize\n",
    "import os\n",
    "import http"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746175dc",
   "metadata": {},
   "source": [
    "### Sourcing Parquet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c37682",
   "metadata": {},
   "source": [
    "Please visit the url https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc039a2-57f4-4b0d-9029-764009d9d38d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:32.562231Z",
     "start_time": "2024-04-09T19:54:32.556578Z"
    }
   },
   "outputs": [],
   "source": [
    "# check current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b5dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:38.264709Z",
     "start_time": "2024-04-09T19:54:36.573452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data from the Parquet file. We use pandas read_parquet method for ease and speed.\n",
    "df_parquet = pd.read_parquet(\"yellow_tripdata_2022-01.parquet\")\n",
    "#get row count of df\n",
    "print(df_parquet.shape[0])\n",
    "#get column count of df\n",
    "print(df_parquet.shape[1])\n",
    "#get size on disk of file\n",
    "print(os.path.getsize(\"yellow_tripdata_2022-01.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763199bd-0487-4cb1-aee8-b3739e653b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:40.228906Z",
     "start_time": "2024-04-09T19:54:40.200512Z"
    }
   },
   "outputs": [],
   "source": [
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb911f7-9aac-463d-9f2b-1a3c533def46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:43.441974Z",
     "start_time": "2024-04-09T19:54:43.394135Z"
    }
   },
   "outputs": [],
   "source": [
    "#show average \"trip_distance\", average \"fare_amount\", and average \"tip_amount\" from df columns\n",
    "print(f\"Average trip distance: {df_parquet['trip_distance'].mean()} \")\n",
    "print(f\"Average fare amount: {df_parquet['fare_amount'].mean()} \")\n",
    "print(f\"Average tip amount: {df_parquet['tip_amount'].mean()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2f93c",
   "metadata": {},
   "source": [
    "### Sourcing CSV data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a306a2",
   "metadata": {},
   "source": [
    "Please visit the url https://data.cityofnewyork.us/resource/h9gi-nx95.csv?$limit=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56007303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:49.016279Z",
     "start_time": "2024-04-09T19:54:48.976155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data from the CSV file. We use pandas read_csv method for ease and speed.\n",
    "df_csv = pd.read_csv(\"h9gi-nx95.csv\")\n",
    "df_csv.head()\n",
    "#get row count of df\n",
    "print(df_csv.shape[0])\n",
    "#get size on disk of file\n",
    "print(os.path.getsize(\"h9gi-nx95.csv\"))\n",
    "#show total number of crash counts grouped by column \"contributing_factor_vehicle_1\"\n",
    "df_csv['contributing_factor_vehicle_1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da41e6",
   "metadata": {},
   "source": [
    "### Sourcing data from APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc77b5",
   "metadata": {},
   "source": [
    "Please make sure to install the certifi library using - pipenv install certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed4814-046e-4a12-b85e-ec07f75ba42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:54:56.030521Z",
     "start_time": "2024-04-09T19:54:54.961533Z"
    }
   },
   "outputs": [],
   "source": [
    "# get api data from url\n",
    "url = 'https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500'\n",
    "\n",
    "# Check if API is available to retrive the data\n",
    "apt_status = request('GET', url).status # removed \"http.\" from in front of request\n",
    "print(apt_status)\n",
    "if apt_status == 200:\n",
    "    # Sometimes we get certificate error . We should never silence this error as this may cause a security threat.\n",
    "    # Create a Pool manager that can be used to read the API response \n",
    "    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "    data = json.loads(http.request('GET', url).data.decode('utf-8'))\n",
    "    df_api = pd.json_normalize(data)\n",
    "else:\n",
    "    df_api = pd.Dataframe()\n",
    "df_api.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20bb79-f8d8-42a0-8709-0af81aed724c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T19:56:54.036633Z",
     "start_time": "2024-04-09T19:56:53.997998Z"
    }
   },
   "outputs": [],
   "source": [
    "#print row count of df_api\n",
    "print(df_api.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596e69693ec86fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:14:15.285885Z",
     "start_time": "2024-04-09T20:14:15.269246Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#convert column \"crash_time\" to hour of day\n",
    "print(\"Crash Time as datetime:\")\n",
    "df_api['crash_time'] = pd.to_datetime(df_api['crash_time'])\n",
    "\n",
    "#print new list of crash_time values in new datetime format, showing the hour of day and am/pm\n",
    "print(\"Crash Time as datetime formatted as hour (am/pm):\")\n",
    "print(df_api['crash_time'].dt.strftime('%I %p'))\n",
    "\n",
    "#print count of records grouped by \"crash_date\"\n",
    "print(\"Count of records grouped by crash_date:\")\n",
    "print(df_api['crash_date'].value_counts())\n",
    "\n",
    "#print the count of records grouped by crash_time as hour of day, sorted by sum count descending\n",
    "print(\"Count of records grouped by crash_time as hour of day:\")\n",
    "#add headers to the output\n",
    "print(\"Hour of Day: Count\")\n",
    "print(df_api['crash_time'].dt.hour.value_counts().sort_values(ascending=False))\n",
    "\n",
    "#convert the crash_time to seconds from midnight \n",
    "seconds_since_midnight = df_api['crash_time'].dt.hour*3600 + df_api['crash_time'].dt.minute*60 + df_api['crash_time'].dt.second\n",
    "#calculate the average crash time in seconds\n",
    "average_crash_time = seconds_since_midnight.mean()\n",
    "#convert avg seconds back to HH:MM:SS format\n",
    "average_crash_time = pd.to_datetime(average_crash_time, unit='s').strftime('%H:%M:%S')\n",
    "print(f\"The average crash time is: {average_crash_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fc78f",
   "metadata": {},
   "source": [
    "### Sourcing Data from RDBMS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a384b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:16:07.640741Z",
     "start_time": "2024-04-09T20:16:07.463106Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Read sqlite query results into a pandas DataFrame\n",
    "# with sqlite3.connect(\"movies.sqlite\") as conn:\n",
    "#     df = pd.read_sql(\"SELECT * from movies\", conn)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e7998c62f492e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:27:16.258200Z",
     "start_time": "2024-04-09T20:27:15.844736Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test using pyodbc\n",
    "import pyodbc\n",
    "\n",
    "#import pyodbc\n",
    "#connect to sql database\n",
    "with pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=datadevjobs.d.db.vu.local;DATABASE=DataDevJobsRepo;Trusted_Connection=yes;') as conn:\n",
    "    query = \"SELECT * FROM Logging.SolutionOverviewServers\"\n",
    "    df_sql = pd.read_sql(query, conn)\n",
    "df_sql.head()\n",
    "\n",
    "# with pyodbc, open connection to sql database \"datadevjobs.d.db.vu.local\"\n",
    "    #read the db \"DataDevJobsRepo\" and table \"Logging.SolutionOverviewServers\" into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad90affc3ad432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:59:58.302623Z",
     "start_time": "2024-04-09T20:59:56.498203Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test using sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#connect to sql database\n",
    "engine = create_engine('mssql+pyodbc://datadevjobs.d.db.vu.local/DataDevJobsRepo?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "with engine.connect() as conn:\n",
    "    df_sqlalchemy = pd.read_sql(\"SELECT * FROM Logging.SolutionOverviewServers\", conn)\n",
    "df_sqlalchemy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab324ee5",
   "metadata": {},
   "source": [
    "# Sourcing data from Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff92439",
   "metadata": {},
   "source": [
    "Please visit the url https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97c5fffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T13:44:04.251787Z",
     "start_time": "2024-04-10T13:44:03.414698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Country/Territory UN region IMF[1][13]            World Bank[14]  \\\n    Country/Territory UN region   Forecast       Year       Estimate   \n0               World         —  104476432       2023      100562011   \n1       United States  Americas   26949643       2023       25462700   \n2               China      Asia   17700899  2023[n 1]       17963171   \n3             Germany    Europe    4429838       2023        4072192   \n4               Japan      Asia    4230862       2023        4231141   \n..                ...       ...        ...        ...            ...   \n208             Palau   Oceania        267       2023              —   \n209          Kiribati   Oceania        246       2023            223   \n210             Nauru   Oceania        150       2023            151   \n211        Montserrat  Americas          —          —              —   \n212            Tuvalu   Oceania         63       2023             60   \n\n               United Nations[15]             \n          Year           Estimate       Year  \n0         2022           96698005       2021  \n1         2022           23315081       2021  \n2    2022[n 3]           17734131  2021[n 1]  \n3         2022            4259935       2021  \n4         2022            4940878       2021  \n..         ...                ...        ...  \n208          —                218       2021  \n209       2022                227       2021  \n210       2022                155       2021  \n211          —                 72       2021  \n212       2022                 60       2021  \n\n[213 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Country/Territory</th>\n      <th>UN region</th>\n      <th colspan=\"2\" halign=\"left\">IMF[1][13]</th>\n      <th colspan=\"2\" halign=\"left\">World Bank[14]</th>\n      <th colspan=\"2\" halign=\"left\">United Nations[15]</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>Country/Territory</th>\n      <th>UN region</th>\n      <th>Forecast</th>\n      <th>Year</th>\n      <th>Estimate</th>\n      <th>Year</th>\n      <th>Estimate</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>World</td>\n      <td>—</td>\n      <td>104476432</td>\n      <td>2023</td>\n      <td>100562011</td>\n      <td>2022</td>\n      <td>96698005</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>United States</td>\n      <td>Americas</td>\n      <td>26949643</td>\n      <td>2023</td>\n      <td>25462700</td>\n      <td>2022</td>\n      <td>23315081</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>China</td>\n      <td>Asia</td>\n      <td>17700899</td>\n      <td>2023[n 1]</td>\n      <td>17963171</td>\n      <td>2022[n 3]</td>\n      <td>17734131</td>\n      <td>2021[n 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Germany</td>\n      <td>Europe</td>\n      <td>4429838</td>\n      <td>2023</td>\n      <td>4072192</td>\n      <td>2022</td>\n      <td>4259935</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Japan</td>\n      <td>Asia</td>\n      <td>4230862</td>\n      <td>2023</td>\n      <td>4231141</td>\n      <td>2022</td>\n      <td>4940878</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>Palau</td>\n      <td>Oceania</td>\n      <td>267</td>\n      <td>2023</td>\n      <td>—</td>\n      <td>—</td>\n      <td>218</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>Kiribati</td>\n      <td>Oceania</td>\n      <td>246</td>\n      <td>2023</td>\n      <td>223</td>\n      <td>2022</td>\n      <td>227</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>Nauru</td>\n      <td>Oceania</td>\n      <td>150</td>\n      <td>2023</td>\n      <td>151</td>\n      <td>2022</td>\n      <td>155</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>Montserrat</td>\n      <td>Americas</td>\n      <td>—</td>\n      <td>—</td>\n      <td>—</td>\n      <td>—</td>\n      <td>72</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>Tuvalu</td>\n      <td>Oceania</td>\n      <td>63</td>\n      <td>2023</td>\n      <td>60</td>\n      <td>2022</td>\n      <td>60</td>\n      <td>2021</td>\n    </tr>\n  </tbody>\n</table>\n<p>213 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from url\n",
    "df_html = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)',match = 'by country') # the match parameter filters results to only tables with a specific string in the html \"caption\" tag\n",
    "# Let's see how many tables are there with tag ' by county'\n",
    "print(len(df_html)) # There are 4 tables\n",
    "# Let's see the first table\n",
    "df_html[0]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "80282184e3a54089"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
